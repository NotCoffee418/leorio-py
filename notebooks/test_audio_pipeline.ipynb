{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import importlib\n",
    "from IPython.display import Audio\n",
    "import sounddevice as sd\n",
    "import wave\n",
    "import time\n",
    "from scipy.signal import butter, filtfilt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logic.utils.io_access as io\n",
    "import logic.audio_systems.device_helpers as dh\n",
    "import logic.audio_systems.audio_transformers as at\n",
    "import logic.audio_systems.speech_audio_stream_observable as saso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force reload imports\n",
    "importlib.reload(dh)\n",
    "importlib.reload(at)\n",
    "importlib.reload(saso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_index = dh.find_seed_device_index()\n",
    "device_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = sd.query_devices()\n",
    "target_description = \"seeed-2mic-voicecard\"\n",
    "for i, device in enumerate(devices):\n",
    "    if device['name'].startswith(target_description):\n",
    "        print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels_count = 2\n",
    "output_channels_count = 1\n",
    "sample_rate = 44100\n",
    "record_seconds = 5\n",
    "testfile_path = io.get_path('data', 'test_audio_pipeline.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record audio internally for notebook\n",
    "class AudioDataObserver:\n",
    "    def __init__(self, duration):\n",
    "        self.filename = testfile_path\n",
    "        self.rate = sample_rate\n",
    "        self.channels = output_channels_count\n",
    "        self.duration = duration\n",
    "        self.binary_audio_data = bytearray()\n",
    "        self.frames = int(sample_rate * duration)\n",
    "        self.frame_count = 0\n",
    "\n",
    "    def on_received(self, audio_data):\n",
    "        self.binary_audio_data.extend(audio_data)\n",
    "    \n",
    "    # this is binary int16 data\n",
    "    def get_binary_audio_data(self):\n",
    "        return self.binary_audio_data\n",
    "    \n",
    "    def clear_audio_data():\n",
    "        self.binary_audio_data = bytearray()\n",
    "        self.frame_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record 5 seconds of audio\n",
    "audio_stream_observable = saso.SpeechAudioStreamObservable()\n",
    "audio_stream_observer = AudioDataObserver(record_seconds)\n",
    "audio_stream_observable.add_observer(audio_stream_observer)\n",
    "\n",
    "# Start the audio stream\n",
    "try:\n",
    "    print(\"Recording audio for 3 seconds...\")\n",
    "    time.sleep(record_seconds)\n",
    "finally:\n",
    "    print(\"Done recording.\")\n",
    "    audio_stream_observable.stop()\n",
    "    \n",
    "# Get recording binary\n",
    "binary_recording_data = audio_stream_observer.get_binary_audio_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array waves\n",
    "np_input = at.bytes_to_int16(binary_recording_data)\n",
    "\n",
    "# Play the audio\n",
    "display(Audio(np_input, rate=sample_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize recoding\n",
    "# Create the plots\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 6))\n",
    "\n",
    "# Plot left channel\n",
    "axs[0].plot(np_input)\n",
    "axs[0].set_title('Left Channel')\n",
    "axs[0].set_xlabel('Sample number')\n",
    "axs[0].set_ylabel('Amplitude')\n",
    "\n",
    "# Plot right channel\n",
    "axs[1].plot(np_input)\n",
    "axs[1].set_title('Right Channel')\n",
    "axs[1].set_xlabel('Sample number')\n",
    "axs[1].set_ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min after processing:\", np.min(np_input))\n",
    "print(\"Max after processing:\", np.max(np_input))\n",
    "print(\"Input data type:\", np_input.dtype)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
