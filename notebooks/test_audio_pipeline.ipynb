{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import importlib\n",
    "from IPython.display import Audio\n",
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "from scipy.signal import butter, filtfilt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logic.utils.io_access as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force reload imports\n",
    "#importlib.reload(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seed_device_index():\n",
    "    p = pyaudio.PyAudio()\n",
    "    device_count = p.get_device_count()\n",
    "    target_description = \"seeed-2mic-voicecard\"\n",
    "\n",
    "    for i in range(device_count):\n",
    "        device_info = p.get_device_info_by_index(i)\n",
    "        if device_info.get('maxInputChannels') > 0:\n",
    "            device_name = device_info.get('name')\n",
    "            if target_description in device_name:\n",
    "                p.terminate()\n",
    "                return i\n",
    "\n",
    "    p.terminate()\n",
    "    raise Exception(\n",
    "        f\"Device with description containing '{target_description}' not found\")\n",
    "device_index = find_seed_device_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_to_np(bytes_data):\n",
    "    return np.frombuffer(bytes_data, dtype=np.float32)\n",
    "\n",
    "\n",
    "def np_to_bytes(np_data):\n",
    "    return np_data.astype(np.float32).tobytes()\n",
    "\n",
    "\n",
    "def filter_human_speech_only(np_channel, sample_rate):\n",
    "    # Normalize the audio data\n",
    "    np_channel_normalized = np_channel / 32768.0\n",
    "\n",
    "    # Filter design parameters\n",
    "    order = 5\n",
    "    nyquist = 0.5 * sample_rate\n",
    "    low = 300.0 / nyquist\n",
    "    high = 3400.0 / nyquist\n",
    "\n",
    "    # Design and apply the filter\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    y = filtfilt(b, a, np_channel_normalized)\n",
    "\n",
    "    # Scale back and clip the values to int16 range\n",
    "    y = np.clip(y * 32768.0, -32768, 32767)\n",
    "\n",
    "    # Convert the datatype to int16\n",
    "    y = y.astype(np.int16)\n",
    "    return y\n",
    "\n",
    "\n",
    "def volume_boost(np_channel, volume_ratio):\n",
    "    # Volume boost & prevent clipping\n",
    "    return np.clip(np_channel * volume_ratio, -1, 1)\n",
    "\n",
    "\n",
    "def seperate_channels(np_data):\n",
    "    left_channel = np_data[::2]\n",
    "    right_channel = np_data[1::2]\n",
    "    return left_channel, right_channel\n",
    "\n",
    "\n",
    "def merge_two_channels(np_left_channel, np_right_channel):\n",
    "    return (np_left_channel + np_right_channel) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels_count = 2\n",
    "output_channels_count = 1\n",
    "sample_rate = 44100\n",
    "record_seconds = 5\n",
    "testfile_path = io.get_path('data', 'test.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechAudioStreamObservable:\n",
    "    def __init__(self):\n",
    "        # Set hardcoded values\n",
    "        self.rate = sample_rate\n",
    "        self.channels = input_channels_count\n",
    "        self.format = pyaudio.paFloat32\n",
    "        self.frames_per_buffer = 1024\n",
    "        self.input_device_index = device_index\n",
    "        self.observers = []\n",
    "\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(\n",
    "            format=self.format,\n",
    "            channels=self.channels,\n",
    "            rate=self.rate,\n",
    "            input_device_index=self.input_device_index,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.frames_per_buffer,\n",
    "            stream_callback=self._callback\n",
    "        )\n",
    "\n",
    "    def _callback(self, in_data, frame_count, time_info, status):\n",
    "        # Convert to np & seperate stereo channels\n",
    "        np_input = bytes_to_np(in_data)\n",
    "        np_left, np_right = seperate_channels(np_input)\n",
    "\n",
    "        # Filter to human speech frequencies\n",
    "        # WIP: We need fix whitenoise first, then test again\n",
    "        #np_left = filter_human_speech_only(np_left, self.rate)\n",
    "        #np_right = filter_human_speech_only(np_right, self.rate)\n",
    "\n",
    "        # Volume boost\n",
    "        #np_left = volume_boost(np_left, volume_rate)\n",
    "        #np_right = volume_boost(np_right, volume_rate)\n",
    "\n",
    "        # Merge channels to single mono channel & back to binary\n",
    "        np_input = merge_two_channels(np_left, np_right)\n",
    "        #np_input = np_left\n",
    "        out_data = np_to_bytes(np_input)\n",
    "\n",
    "        # Notify observers\n",
    "        for observer in self.observers:\n",
    "            observer.on_received(out_data)\n",
    "        return (out_data, pyaudio.paContinue)\n",
    "\n",
    "    def start(self):\n",
    "        try:\n",
    "            self.stream.start_stream()\n",
    "        except Exception as ex:\n",
    "            print(f\"An error occurred while starting the stream: {ex}\")\n",
    "\n",
    "    def stop(self):\n",
    "        try:\n",
    "            self.stream.stop_stream()\n",
    "            self.stream.close()\n",
    "            self.p.terminate()\n",
    "        except Exception as ex:\n",
    "            print(f\"An error occurred while stopping the stream: {ex}\")\n",
    "\n",
    "    def add_observer(self, observer):\n",
    "        self.observers.append(observer)\n",
    "\n",
    "    def remove_observer(self, observer):\n",
    "        self.observers.remove(observer)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class AudioDataObserver:\n",
    "    def __init__(self, duration):\n",
    "        self.filename = testfile_path\n",
    "        self.rate = sample_rate\n",
    "        self.channels = output_channels_count\n",
    "        self.duration = duration\n",
    "        self.audio_data = bytearray()\n",
    "        self.frames = int(sample_rate * duration)\n",
    "        self.frame_count = 0\n",
    "\n",
    "    def on_received(self, audio_data):\n",
    "        self.audio_data.extend(audio_data)\n",
    "        # 2 bytes per sample\n",
    "        self.frame_count += len(audio_data) // (self.channels * 2)\n",
    "        if self.frame_count >= self.frames:\n",
    "            with wave.open(self.filename, 'wb') as wf:\n",
    "                wf.setnchannels(self.channels)\n",
    "                wf.setsampwidth(2)  # 2 bytes\n",
    "                wf.setframerate(self.rate)\n",
    "                wf.writeframes(self.audio_data)\n",
    "                \n",
    "    def get_audio_data(self):\n",
    "        return self.audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record 5 seconds of audio\n",
    "audio_stream_observable = SpeechAudioStreamObservable()\n",
    "audio_stream_observer = AudioDataObserver(record_seconds)\n",
    "audio_stream_observable.add_observer(audio_stream_observer)\n",
    "\n",
    "# Start the audio stream\n",
    "audio_stream_observable.start()\n",
    "try:\n",
    "    print(\"Recording audio for 3 seconds...\")\n",
    "    time.sleep(record_seconds)\n",
    "finally:\n",
    "    print(\"Done recording.\")\n",
    "    audio_stream_observable.stop()\n",
    "    \n",
    "# Play the recorded audio\n",
    "recording_data = audio_stream_observer.get_audio_data()\n",
    "Audio(recording_data, rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_input = bytes_to_np(recording_data)\n",
    "\n",
    "# In case of two output channels\n",
    "np_left, np_right = seperate_channels(np_input)\n",
    "display(Audio(np_left, rate=sample_rate))\n",
    "display(Audio(np_right, rate=sample_rate))\n",
    "\n",
    "# In case of one output channel\n",
    "display(Audio(np_input, rate=sample_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize recoding\n",
    "# Create the plots\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 6))\n",
    "\n",
    "# Plot left channel\n",
    "axs[0].plot(np_left)\n",
    "axs[0].set_title('Left Channel')\n",
    "axs[0].set_xlabel('Sample number')\n",
    "axs[0].set_ylabel('Amplitude')\n",
    "\n",
    "# Plot right channel\n",
    "axs[1].plot(np_right)\n",
    "axs[1].set_title('Right Channel')\n",
    "axs[1].set_xlabel('Sample number')\n",
    "axs[1].set_ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(np_right, rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
